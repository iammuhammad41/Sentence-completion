{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6544,"status":"ok","timestamp":1660225770595,"user":{"displayName":"Muhammad Altaf","userId":"03105077489695775624"},"user_tz":-480},"id":"s_EWWH2yRewt","outputId":"fa97b9f2-2dd3-4392-f308-66b5ff57fa1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":582},"executionInfo":{"elapsed":457,"status":"error","timestamp":1660231973625,"user":{"displayName":"Muhammad Altaf","userId":"03105077489695775624"},"user_tz":-480},"id":"kD1OMo8nV8Cj","outputId":"127a062c-94a3-4860-ef91-81cbc6bbb1c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4637d99a2f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# from simple_classical_approach import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mQuestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"__START\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"__END\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-4637d99a2f8d>\u001b[0m in \u001b[0;36mQuestion\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_choices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mget_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mscc_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: get_tokens() missing 1 required positional argument: 'questions'"]}],"source":["# !pip install unet\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","import pandas as pd\n","import os\n","\n","# path\n","dirr = '/content/drive/MyDrive/ColabNotebooks/lab2resources/sentence-completion'\n","# dataloader\n","questions = pd.read_csv(os.path.join(dirr,\"testing_data.csv\"))\n","answer_data = pd.read_csv(os.path.join(dirr,\"test_answer.csv\"))\n","\n","import os,random,math,sys\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from nltk.tokenize import sent_tokenize\n","from nltk.tokenize import word_tokenize\n","from nltk import ne_chunk,ne_chunk_sents,pos_tag,tree2conlltags\n","from nltk.corpus import words\n","import spacy\n","from spacy.lang.en import English\n","from spacy.tokenizer import Tokenizer\n","from tqdm import tqdm\n","nltk.download('words')\n","vocab=words.words()\n","nltk.download('punkt')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')\n","# spacy_nlp = spacy.load(\"en_core_web_sm\")\n","\n","import csv\n","import sys, os\n","sys.path.append(os.getcwd()) # may need to change this\n","# from simple_classical_approach import *\n","\n","class Question():\n","    def get_tokens(self,questions):\n","        return [\"__START\"]+tokenize(self.fields[questions.colnames[\"question\"]])+[\"__END\"]\n","    \n","    def getting_left_context(self,window=1,target=\"_____\"):\n","        found=-1\n","        sent_tokens=self.get_tokens()\n","        for i,token in enumerate(sent_tokens):\n","            if token==target:\n","                found=i\n","                break  \n","            \n","        if found>-1:\n","            return sent_tokens[i-window:i]\n","        else:\n","            return []\n","\n","    def choose_choices(self,lm,method=\"bigram\",choices=[]):\n","        if choices==[]:\n","            choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n","        if method==\"bigram\":\n","            rc=self.get_right_context(window=1)\n","            lc=self.getting_left_context(window=1)\n","            probs=[lm.get_prob(rc[0],[self.getting_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]})*lm.get_prob(self.getting_field(ch+\")\"),lc,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        elif method==\"bigram_right\":\n","            context=self.get_right_context(window=1)\n","            probs=[lm.get_prob(context[0],[self.getting_field(ch+\")\")],methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        else:\n","            context=self.getting_left_context(window=1)\n","            probs=[lm.get_prob(self.getting_field(ch+\")\"),context,methodparams={\"method\":method.split(\"_\")[0]}) for ch in choices]\n","        maxprob=max(probs)\n","        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n","        #if len(bestchoices)>1:\n","        #    print(\"Randomly choosing from {}\".format(len(bestchoices)))\n","        return np.random.choice(bestchoices)\n","    \n","    def choosing_backoff(self,lm,methods=['bigram','unigram'],choices=[\"a\",\"b\",\"c\",\"d\",\"e\"]):\n","        context=self.getting_left_context(window=1)\n","        probs=[lm.get_prob(self.getting_field(ch+\")\"),context,methodparams={\"method\":methods[0]}) for ch in choices]\n","        maxprob=max(probs)\n","        bestchoices=[ch for ch,prob in zip(choices,probs) if prob == maxprob]\n","        if len(bestchoices)>1:\n","            print(\"Backing off on {}\".format(len(bestchoices)))\n","        return self.choose_choices(lm,choices=bestchoices,method=methods[1])\n","    \n","    def predictions(self,method=\"chooseA\", model='mylm' ):\n","        if method==\"chooseA\":\n","            return self.chooseA()\n","        elif method==\"random\":\n","            return self.chooserandom()\n","        elif method==\"bigram_backoff\":\n","            return self.choosing_backoff(model,methods=[\"bigram\",\"unigram\"])\n","        else:\n","            return self.choose_choices(model,method=method)\n","    \n","class scc_reader:\n","    \n","    def __init__(self,qs=questions,ans=answer_data):\n","        self.qs=qs\n","        self.ans=ans\n","        self.reading_files()\n","        \n","    def reading_files(self):\n","        \n","        #read in the question file\n","        with open(self.qs) as instream:\n","            csvreader=csv.reader(instream)\n","            qlines=list(csvreader)\n","        \n","        #store the column names as a reverse index so they can be used to reference parts of the question\n","        questions.colnames={item:i for i,item in enumerate(qlines[0])}\n","        \n","        #create a question instance for each line of the file (other than heading line)\n","        questions=[questions(qline) for qline in qlines[1:]]\n","        \n","        #read in the answer file\n","        with open(self.ans) as instream:\n","            csvreader=csv.reader(instream)\n","            alines=list(csvreader)\n","            \n","        #add answer_data to question_data so predictions can be checked    \n","        for q,aline in zip(questions,alines[1:]):\n","            q.add_answer(aline)\n","        \n","    def getting_field(self,field):\n","        return [q.getting_field(field) for q in self.questions] \n","    \n","    def predictions(self,method=\"chooseA\"):\n","        return [q.predictions(method=method) for q in self.questions]\n","    \n","    def prediction_and_score(self,method=\"chooseA\"):\n","        scores=[q.prediction_and_score(method=method) for q in questions]\n","        return sum(scores)/len(scores)\n","\n","Question()\n","scc_reader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnQPw4DkKa3Y"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ngram.ipynb","provenance":[{"file_id":"1tWSfhmTUjo4TNeuZ5GDLaSs7O4mZEoiw","timestamp":1659624651176}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}